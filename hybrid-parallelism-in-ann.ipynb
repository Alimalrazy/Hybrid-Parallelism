{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, Flatten\nimport time\n\n# Load MNIST dataset\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Normalize the data\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\n# Flatten each image to a vector with 784 values (since original MNIST images are 28x28)\nx_train = x_train.reshape(-1, 784)\nx_test = x_test.reshape(-1, 784)\n\n# Define the model as specified\nmodel = Sequential([\n    Input(shape=(784,)),  # Adjusted to 784 to match MNIST image vector length\n    Dense(16, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(10, activation=None)  # Output logits\n])\nmodel.compile(optimizer='adam', \n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Start timing\nstart_time = time.time()\n\n# Train the model\nmodel.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n\n# End timing\ntraining_time = time.time() - start_time\n\n# Evaluate the model on the test set (optional, if you want to report accuracy)\nloss, accuracy = model.evaluate(x_test, y_test)\n\n# Print results\nprint(f\"Training Time: {training_time:.2f} seconds\")\nprint(f\"Test Loss: {loss:.2f}, Test Accuracy: {accuracy:.2%}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T15:33:53.807608Z","iopub.execute_input":"2024-06-08T15:33:53.807982Z","iopub.status.idle":"2024-06-08T15:34:29.143007Z","shell.execute_reply.started":"2024-06-08T15:33:53.807953Z","shell.execute_reply":"2024-06-08T15:34:29.142091Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-08 15:33:55.330092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-08 15:33:55.330186: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-08 15:33:55.439295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/5\n\u001b[1m  94/1500\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2380 - loss: 2.1133","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717860850.064594     105 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717860850.079163     105 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1498/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.9486","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717860853.134312     106 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.6908 - loss: 0.9478 - val_accuracy: 0.9158 - val_loss: 0.2828\nEpoch 2/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2669 - val_accuracy: 0.9329 - val_loss: 0.2252\nEpoch 3/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.2119 - val_accuracy: 0.9422 - val_loss: 0.1984\nEpoch 4/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.1872 - val_accuracy: 0.9448 - val_loss: 0.1911\nEpoch 5/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1669 - val_accuracy: 0.9459 - val_loss: 0.1878\n\u001b[1m111/313\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9356 - loss: 0.2213","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717860868.258914     105 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9354 - loss: 0.2209\nTraining Time: 20.67 seconds\nTest Loss: 0.20, Test Accuracy: 94.29%\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717860869.125840     107 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport time\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.datasets import mnist\nimport threading\n\n# Load and prepare the MNIST dataset\n(x, y), (x_test, y_test) = mnist.load_data()\nx = np.expand_dims(x, -1) / 255.0  # Normalize and add channel dimension\nx_resized = tf.image.resize(x, [16, 16])  # Resize images to 16x16\nx_resized = x_resized[..., 0]  # Remove the channels dimension\nx_flattened = tf.reshape(x_resized, [x_resized.shape[0], -1])  # Flatten images\n\nx_test = np.expand_dims(x_test, -1) / 255.0\nx_test_resized = tf.image.resize(x_test, [16, 16])\nx_test_resized = x_test_resized[..., 0]\nx_test_flattened = tf.reshape(x_test_resized, [x_test_resized.shape[0], -1])\n\nx_flattened1 = x_flattened[:, :128]  # First half of the pixels\nx_flattened2 = x_flattened[:, 128:]  # Second half of the pixels\nx_test_flattened1 = x_test_flattened[:, :128]\nx_test_flattened2 = x_test_flattened[:, 128:]\n\nmodels = {}  # Dictionary to store models\n\ndef create_and_train_model(gpu_id, data, labels):\n    \"\"\"Create and train a model on a specific GPU.\"\"\"\n    with tf.device(f'/gpu:{gpu_id}'):\n        model = Sequential([\n            Input(shape=(128,)),\n            Dense(16, activation='relu'),\n            Dense(16, activation='relu'),\n            Dense(16, activation='relu'),\n            Dense(10, activation='softmax')\n        ])\n        model.compile(optimizer='adam', \n                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                      metrics=['accuracy'])\n        print(f\"Starting training on GPU {gpu_id}\")\n        model.fit(data, labels, epochs=5, batch_size=32, validation_split=0.2)\n        models[gpu_id] = model  # Save the model to the global dictionary\n        print(f\"Training completed on GPU {gpu_id}\")\n\ndef run_on_gpu(gpu_id, data, labels):\n    \"\"\"Function to run training on a specific GPU.\"\"\"\n    create_and_train_model(gpu_id, data, labels)\n\n# Setup threading to train on both GPUs concurrently\nthread1 = threading.Thread(target=run_on_gpu, args=(0, x_flattened1, y))\nthread2 = threading.Thread(target=run_on_gpu, args=(1, x_flattened2, y))\n\nstart_time = time.time()\nthread1.start()\nthread2.start()\nthread1.join()\nthread2.join()\nend_time = time.time()\n\n# Output the total time taken\nprint(f\"Total elapsed time: {end_time - start_time:.4f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T15:34:29.144779Z","iopub.execute_input":"2024-06-08T15:34:29.145325Z","iopub.status.idle":"2024-06-08T15:34:54.100402Z","shell.execute_reply.started":"2024-06-08T15:34:29.145298Z","shell.execute_reply":"2024-06-08T15:34:54.099460Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Starting training on GPU 0\nStarting training on GPU 1\nEpoch 1/5\nEpoch 1/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5321 - loss: 1.3576 - val_accuracy: 0.8235 - val_loss: 0.5562\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5711 - loss: 1.3065 - val_accuracy: 0.7843 - val_loss: 0.6252\nEpoch 2/5\nEpoch 2/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.6148 - val_accuracy: 0.8255 - val_loss: 0.5119\nEpoch 3/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8325 - loss: 0.5361 - val_accuracy: 0.8600 - val_loss: 0.4568\nEpoch 3/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.5338 - val_accuracy: 0.8267 - val_loss: 0.4789\nEpoch 4/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.4638 - val_accuracy: 0.8704 - val_loss: 0.4130\nEpoch 4/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8281 - loss: 0.5006 - val_accuracy: 0.8450 - val_loss: 0.4428\nEpoch 5/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8651 - loss: 0.4306 - val_accuracy: 0.8762 - val_loss: 0.3954\nEpoch 5/5\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.4015 - val_accuracy: 0.8832 - val_loss: 0.3746\nTraining completed on GPU 0\n\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.4587 - val_accuracy: 0.8460 - val_loss: 0.4260\nTraining completed on GPU 1\nTotal elapsed time: 23.9005 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"def combine_predictions(model1, model2, data1, data2):\n    \"\"\"Combine predictions from two models by averaging their output probabilities.\"\"\"\n    # Ensure predictions are made on the correct GPUs\n    with tf.device('/gpu:0'):\n        preds1 = model1.predict(data1)\n    with tf.device('/gpu:1'):\n        preds2 = model2.predict(data2)\n    \n    # Average the predictions from both models\n    combined_preds = (preds1 + preds2) / 2\n    return combined_preds\n\ndef calculate_accuracy(predictions, labels):\n    \"\"\"Calculate the accuracy of predictions.\"\"\"\n    predicted_labels = np.argmax(predictions, axis=1)\n    correct_predictions = np.sum(predicted_labels == labels)\n    accuracy = correct_predictions / len(labels)\n    return accuracy\n\n# Use the `models` dictionary which stores trained models\ncombined_preds = combine_predictions(models[0], models[1], x_test_flattened1, x_test_flattened2)\n\n# Compute probabilities using softmax and calculate accuracy\nprobabilities = tf.nn.softmax(combined_preds, axis=1)\nfinal_accuracy = calculate_accuracy(probabilities, y_test)  # Ensure y_test is your actual test labels\nprint(f\"Combined Model Accuracy: {final_accuracy:.4%}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-08T15:34:54.101529Z","iopub.execute_input":"2024-06-08T15:34:54.101849Z","iopub.status.idle":"2024-06-08T15:34:56.063048Z","shell.execute_reply.started":"2024-06-08T15:34:54.101823Z","shell.execute_reply":"2024-06-08T15:34:56.062102Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nCombined Model Accuracy: 93.5200%\n","output_type":"stream"}]}]}